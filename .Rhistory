# Create Vector of Column Max and Min Values
maxs <- apply(College[,2:18], 2, max)
mins <- apply(College[,2:18], 2, min)
# Use scale() and convert the resulting matrix to a data frame
scaled.data <- as.data.frame(scale(College[,2:18],center = mins, scale = maxs - mins))
# Check out results
# print(head(scaled.data,2))
# Convert Private column from Yes/No to 1/0
Private = as.numeric(College$Private)-1
data = cbind(Private,scaled.data)
library(caTools)
set.seed(101)
# Create Split (any column is fine)
split = sample.split(data$Private, SplitRatio = 0.70)
# Split based off of split Boolean Vector
train = subset(data, split == TRUE)
test = subset(data, split == FALSE)
feats <- names(scaled.data)
# Concatenate strings
f <- paste(feats,collapse=' + ')
f <- paste('Private ~',f)
# Convert to formula
f <- as.formula(f)
max_acc <- 0
library(neuralnet)
for(neurons in c(1:100)){
for(layers in c(1:100)){
input <- rep(neurons, layers)
nn <- neuralnet(f,train,hidden=input,linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
if(accuracy > max_acc){
max_acc <- accuracy
}
}
}
cat("The maximum accuracy achieved is: ",max_acc,"\n")
nn <- neuralnet(f,train,hidden=c(10,10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
nn <- neuralnet(f,train,hidden=c(10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(100,100,100,100),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(10,10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
input <- rep(neurons, layers)
nn <- neuralnet(f,train,hidden=c(15,15,15,15,15),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(10,15,10,15,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(15,10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(10,10,10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(12,12,12,12,12),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(9,9,9,9,9),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(10,10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
accuracy <- round((correct/(correct+wrong))*100,2)
cat("The accuracy of the model is: ",accuracy,"\n")
plot(nn)
nn <- neuralnet(f,train,hidden=c(10,10,10,10),linear.output=FALSE)
# Compute Predictions off Test Set
predicted.nn.values <- compute(nn,test[2:18])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
predictions <- table(test$Private,predicted.nn.values$net.result)
# Compute Accuracy of model based off Test predictions
correct <- predictions[1,1]+predictions[2,2]
wrong <- predictions[1,2]+predictions[2,1]
View(test)
install.packages(c("httr", "knitr", "NLP", "rlang"))
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
model <- mx.mlp(data.matrix(train_data), train_label,
hidden_node=ncol(train_data), out_node=1,
out_activation="rmse",
num.round=50, array.batch.size=15, learning.rate=0.07,
momentum=0.9, eval.metric=mx.metric.rmse)
## View developed model:
mx.viz.plot_network(model)
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions)
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
model <- mx.mlp(data.matrix(train_data), train_label,
hidden_node=ncol(train_data), out_node=1,
out_activation="rmse",
num.round=50, array.batch.size=15, learning.rate=0.07,
momentum=0.9, eval.metric=mx.metric.rmse)
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions)
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
model <- mx.mlp(data.matrix(train_data), train_label,
hidden_node=ncol(train_data), out_node=1,
out_activation="rmse",
num.round=50, array.batch.size=15, learning.rate=0.07,
momentum=0.9, eval.metric=mx.metric.rmse)
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions)
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
clear
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
model <- mx.mlp(data.matrix(train_data), train_label,
hidden_node=ncol(train_data), out_node=1,
out_activation="rmse",
num.round=50, array.batch.size=15, learning.rate=0.07,
momentum=0.9, eval.metric=mx.metric.rmse)
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions)
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
model <- mx.mlp(data.matrix(train_data), train_label,
hidden_node=ncol(train_data), out_node=1,
out_activation="rmse",
num.round=50, array.batch.size=15, learning.rate=0.07,
momentum=0.9, eval.metric=mx.metric.rmse)
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions)
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
model <- mx.mlp(data.matrix(train_data), train_label,
hidden_node=ncol(train_data), out_node=1,
out_activation="rmse",
num.round=50, array.batch.size=15, learning.rate=0.07,
momentum=0.9, eval.metric=mx.metric.rmse)
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions)
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
model <- mx.mlp(data.matrix(train_data), train_label,
hidden_node=ncol(train_data), out_node=1,
out_activation="rmse",
num.round=50, array.batch.size=15, learning.rate=0.07,
momentum=0.9, eval.metric=mx.metric.rmse)
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions)
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
setwd("~/R")
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
setwd("~/R/Diabetes_Test")
## MXNet and Predicitve Analytics POC on Prime Indians Diabetes Database.
## Dataset source: https://www.kaggle.com/uciml/pima-indians-diabetes-database
## Load data
data <- read.csv("diabetes.csv")
## Split data into training and test with 70/30 ratio
require(caTools)
split <- sample.split(data, SplitRatio = 0.70)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
## Process train dataset to extract parameters and labels.
train_label <- train[,ncol(train)]
train_data <- train[c(1:ncol(train)-1)]
## Normalize training data.
train_data <- scale(train_data)
## Process test dataset to extract parameters and labels.
test_label <- test[,ncol(test)]
test_data <- test[c(1:ncol(test)-1)]
## Normalize training data.
test_data <- scale(test_data)
## Create network model and train using MXNet:
require(mxnet)
mx.set.seed(101)
# configure a two layer neuralnetwork
data = mx.symbol.Variable('data')
fc1 = mx.symbol.FullyConnected(data, name='fc1', num_hidden=128)
act1 = mx.symbol.Activation(fc1, name='relu1', act_type='relu')
fc2 = mx.symbol.FullyConnected(act1, name='fc2', num_hidden=64)
softmax = mx.symbol.SoftmaxOutput(fc2, name='sm')
model <- mx.model.FeedForward.create(symbol=softmax,
X=data.matrix(train_data),y=train_label,
ctx=mx.cpu(0), num.round=50, learning.rate=0.7,
momentum=0.9, eval.metric=mx.metric.rmse,
wd=0.001, epoch.end.callback=mx.callback.save.checkpoint("diabetes_model"),
batch.end.callback=mx.callback.log.speedometer(batch.size=20, frequency = 100))
## Predict outcome using developed model:
predictions <- predict(model, data.matrix(test_data))
predictions <- round(predictions[2,])
## Calculate model accuracy
classes <- table(predictions, test_label)
accuracy <- ((classes["0","0"]+classes["1","1"])/nrow(test_data))*100
cat("The accuracy of the model is: ", accuracy)
graph.viz(model$symbol)
graph.viz(model$symbol, color=black)
graph.viz(model$symbol)
View(graph.viz)
View(graph.viz)
View(graph.viz)
graph.viz(model$symbol$as.json())
graph.viz(model$as.json())
graph.viz(model$symbol$as.json())
classes
